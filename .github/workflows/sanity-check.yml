name: Search Engine Build & Test

on:
  push:
    branches: [ "main", "master" ]
  pull_request:
    branches: [ "main", "master" ]

jobs:
  build-and-check:
    runs-on: ubuntu-latest

    steps:
    # 1. Get the code
    - name: Checkout Code
      uses: actions/checkout@v4

    # --- C++ SEARCH ENGINE PART ---
    - name: Install C++ Tools
      run: sudo apt-get install -y cmake build-essential

    - name: Configure CMake
      # This prepares the build folder based on your root CMakeLists.txt
      run: cmake -S . -B build

    - name: Compile Search Engine
      # This actually runs 'make' to generate the executable
      run: cmake --build build

    # --- PYTHON CRAWLER PART ---
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Crawler Dependencies
      run: |
        python -m pip install --upgrade pip
        # If you have a requirements.txt, use it. Otherwise, install common libs.
        if [ -f crawler/requirements.txt ]; then pip install -r crawler/requirements.txt; fi
        # Installing common crawler libs just in case you don't have requirements.txt yet
        pip install requests beautifulsoup4

    - name: Crawler Syntax Check
      # This checks if the script is valid Python without running the infinite crawl
      run: python -m py_compile crawler/crawler.py